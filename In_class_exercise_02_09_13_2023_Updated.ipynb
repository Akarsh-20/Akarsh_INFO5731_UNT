{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW5_oFVd9-pY"
      },
      "source": [
        "## The second In-class-exercise (09/13/2023, 40 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAzh1U0sE5I5"
      },
      "source": [
        "Kindly use the provided .ipynb document to write your code or respond to the questions. Avoid generating a new file.\n",
        "Execute all the cells before your final submission."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpgvZQdRE-HV"
      },
      "source": [
        "This in-class exercise is due tomorrow September 14, 2023 at 11:59 PM. No late submissions will be considered."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QBZI-je9-pZ"
      },
      "source": [
        "The purpose of this exercise is to understand users' information needs, then collect data from different sources for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWoKpYQT9-pa"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting research question (or practical question or something innovative) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LmNR3kw9-pa"
      },
      "outputs": [],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "How do the characteristics of acquirer companies (such as their size, industry, or financial performance) influence M&A transactions?\"\n",
        "Problem Description:\n",
        "The objective of this research is to investigate the relationship between the characteristics of acquirer companies and their involvement in M&A transactions.\n",
        "By analyzing the provided dataframe, we can explore various factors related to acquirer companies, such as their financial strength, acquisition strategies,\n",
        "and industry focus, to gain insights into the dynamics of M&A activity.\n",
        "\n",
        "To address the problem we need a statistical list of Aquirers and the Acquisition data over 5 years.\n",
        "\n",
        "My plan involves selecting a website that maintains a comprehensive list of M&A transactions in order to conduct web scraping. By leveraging web scraping techniques,\n",
        "I aim to extract valuable data from this website for further analysis. To begin, I will identify a suitable website that specializes in tracking M&A activity,\n",
        "such as financial news platforms or industry-specific publications. It is essential to review the website's terms of service to ensure compliance with legal guidelines for web scraping.\n",
        "Once the website is selected, I will choose a web scraping tool, such as BeautifulSoup or Selenium, to automate the data extraction process. Developing a scraping script will involve\n",
        "navigating the website, locating the M&A transaction data, and extracting the necessary information. By successfully implementing this plan, I will be able to build a comprehensive dataset\n",
        "of M&A transactions, enabling in-depth research and analysis in the field of mergers and acquisitions.\n",
        "\n",
        "The amount of data required for analysis in M&A studies can vary depending on the research objectives, complexity of the analysis, and available resources.\n",
        "For smaller datasets, saving the data as flat files (e.g., CSV or Excel files) can be a convenient option. In case of Larger Datasets using a relational database management system (RDBMS)\n",
        "like MySQL, PostgreSQL, or SQLite can be beneficial.\n",
        "\n",
        "STEPS TO GET DATA AND IMPORTING IT TO A DATAFRAME AS FOLLOWS:\n",
        "\n",
        "Surf through internet to find a good website which has good Data about M&A.\n",
        "Installing and importing all necessary packages into the current ipynb file.\n",
        "Formulating all reusable algorithms to be able to use to extract the data from a website.\n",
        "Getting the Raw data from HTML into a dictionary.\n",
        "Covert all the raw data into dataframes and merge them together.\n",
        "Pre-process the final dataframe to get required output.\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlxTLRNm9-pa"
      },
      "source": [
        "Question 2 (10 points): Write python code to collect 1000 data samples you discussed above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "QpWOgjHi9-pa",
        "outputId": "833022e1-abcf-40e4-b5c5-fb775efd731f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0409eb51-fe92-41fe-b3b3-739de7b5c095\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DATE</th>\n",
              "      <th>SYMBOL</th>\n",
              "      <th>COMPANY NAME</th>\n",
              "      <th>AQUIRER</th>\n",
              "      <th>AQUIRER NAME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Dec 31, 2014</td>\n",
              "      <td>FFKY</td>\n",
              "      <td>First Financial Service Corp</td>\n",
              "      <td>YCB</td>\n",
              "      <td>Your Community Bankshares Inc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dec 31, 2014</td>\n",
              "      <td>SWS</td>\n",
              "      <td>Sws Group Inc</td>\n",
              "      <td>HTH</td>\n",
              "      <td>Hilltop Holdings Inc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Dec 30, 2014</td>\n",
              "      <td>MWRX</td>\n",
              "      <td>Mergeworthrx Corp</td>\n",
              "      <td>-</td>\n",
              "      <td>Aerocare Holdings Inc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dec 22, 2014</td>\n",
              "      <td>OPLK</td>\n",
              "      <td>Oplink Communications Inc</td>\n",
              "      <td>-</td>\n",
              "      <td>Koch Industries Inc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1005</th>\n",
              "      <td>Apr 14, 2023</td>\n",
              "      <td>CIH</td>\n",
              "      <td>China Index Holdings Ltd.</td>\n",
              "      <td>-</td>\n",
              "      <td>Fang Holdings Limited</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1006</th>\n",
              "      <td>Apr 14, 2023</td>\n",
              "      <td>CIH</td>\n",
              "      <td>China Index Holdings Ltd.</td>\n",
              "      <td>-</td>\n",
              "      <td>Ace Smart Investments Limited</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1007</th>\n",
              "      <td>Apr 11, 2023</td>\n",
              "      <td>NVCN</td>\n",
              "      <td>Neovasc Inc</td>\n",
              "      <td>SWAV</td>\n",
              "      <td>Shockwave Medical Inc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1008</th>\n",
              "      <td>Apr 11, 2023</td>\n",
              "      <td>AMYT</td>\n",
              "      <td>Amryt Pharma PLC</td>\n",
              "      <td>-</td>\n",
              "      <td>Chiesi Farmaceutici SpA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1009</th>\n",
              "      <td>Apr 3, 2023</td>\n",
              "      <td>APEN</td>\n",
              "      <td>Apollo Endosurgery Inc</td>\n",
              "      <td>BSX</td>\n",
              "      <td>Boston Scientific Corp</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1010 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0409eb51-fe92-41fe-b3b3-739de7b5c095')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0409eb51-fe92-41fe-b3b3-739de7b5c095 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0409eb51-fe92-41fe-b3b3-739de7b5c095');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f65541b4-2a58-4569-878d-5a082ed064e5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f65541b4-2a58-4569-878d-5a082ed064e5')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f65541b4-2a58-4569-878d-5a082ed064e5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "              DATE SYMBOL                  COMPANY NAME AQUIRER  \\\n",
              "0             None   None                          None    None   \n",
              "1     Dec 31, 2014   FFKY  First Financial Service Corp     YCB   \n",
              "2     Dec 31, 2014    SWS                 Sws Group Inc     HTH   \n",
              "3     Dec 30, 2014   MWRX             Mergeworthrx Corp       -   \n",
              "4     Dec 22, 2014   OPLK     Oplink Communications Inc       -   \n",
              "...            ...    ...                           ...     ...   \n",
              "1005  Apr 14, 2023    CIH     China Index Holdings Ltd.       -   \n",
              "1006  Apr 14, 2023    CIH     China Index Holdings Ltd.       -   \n",
              "1007  Apr 11, 2023   NVCN                   Neovasc Inc    SWAV   \n",
              "1008  Apr 11, 2023   AMYT              Amryt Pharma PLC       -   \n",
              "1009   Apr 3, 2023   APEN        Apollo Endosurgery Inc     BSX   \n",
              "\n",
              "                       AQUIRER NAME  \n",
              "0                              None  \n",
              "1     Your Community Bankshares Inc  \n",
              "2              Hilltop Holdings Inc  \n",
              "3             Aerocare Holdings Inc  \n",
              "4               Koch Industries Inc  \n",
              "...                             ...  \n",
              "1005          Fang Holdings Limited  \n",
              "1006  Ace Smart Investments Limited  \n",
              "1007          Shockwave Medical Inc  \n",
              "1008        Chiesi Farmaceutici SpA  \n",
              "1009         Boston Scientific Corp  \n",
              "\n",
              "[1010 rows x 5 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "def DataExtract(table):\n",
        "    data = []\n",
        "    for row in table.find_all(\"tr\"):\n",
        "        row_data = []\n",
        "        for cell in row.find_all(\"td\"):\n",
        "            row_data.append(cell.text.strip())\n",
        "        data.append(row_data)\n",
        "    return data\n",
        "\n",
        "baseYear = \"2014\"\n",
        "year = \"2014\"\n",
        "df = pd.DataFrame()\n",
        "baseURL = \"https://stockanalysis.com/actions/acquisitions/\"\n",
        "\n",
        "# LOOPING THE DATA EXTRACTION TO ACHEIVE DATA OF 500 ROWS OF DIFFERENT YEARS\n",
        "for i in range(10):\n",
        "    url = baseURL + year +\"/\"\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    table = soup.find(\"table\", class_=\"svelte-1jtwn20\")\n",
        "    data = DataExtract(table)\n",
        "\n",
        "    baseYear = year\n",
        "    yearIncrement = int(year) +1\n",
        "    year = str(yearIncrement)\n",
        "\n",
        "\n",
        "\n",
        "    if baseYear == \"2014\":\n",
        "        df = pd.DataFrame(data)\n",
        "    else:\n",
        "        df2 = pd.DataFrame(data)\n",
        "        df_combined = pd.concat([df, df2])\n",
        "        df_combined = df_combined.reset_index(drop=True)\n",
        "        df = df_combined\n",
        "\n",
        "df_combined.columns = ['DATE', 'SYMBOL', 'COMPANY NAME', 'AQUIRER', 'AQUIRER NAME']\n",
        "df_combined"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "px6wgvog9-pa"
      },
      "source": [
        "Question 3 (10 points): Write python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/), or ACM Digital Libraries (https://dl.acm.org/) with the keyword \"information retrieval\". The articles should be published in the last 10 years (2013-2023).\n",
        "\n",
        "The following information of the article needs to be collected:\n",
        "\n",
        "(1) Title\n",
        "\n",
        "(2) Venue/journal/conference being published\n",
        "\n",
        "(3) Year\n",
        "\n",
        "(4) Authors\n",
        "\n",
        "(5) Abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9ZlSQe6oEAR",
        "outputId": "768ce3f3-8fcc-4b5b-a4ec-425e9bb6feae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Found article: Information retrieval as statistical translation (2017) (A Berger, J Lafferty - ACM SIGIR Forum,  - dl.acm.org) (… There is a large literature on probabilistic approaches to information retrieval, and we will \n",
            "not attempt to survey it here. Instead, we focus on the language modeling approach introduced …) (… There is a large literature on probabilistic approaches to information retrieval, and we will \n",
            "not attempt to survey it here. Instead, we focus on the language modeling approach introduced …)\n",
            "\n",
            "Found article: [BOOK][B] Information retrieval: Implementing and evaluating search engines (2016) (S Buttcher, CLA Clarke, GV Cormack -  - books.google.com) (… Information retrieval forms the foundation for modern search engines. In this textbook we \n",
            "provide an introduction to information retrieval targeted at graduate students and working …) (… Information retrieval forms the foundation for modern search engines. In this textbook we \n",
            "provide an introduction to information retrieval targeted at graduate students and working …)\n",
            "\n",
            "Found article: A language modeling approach to information retrieval (2017) (JM Ponte, WB Croft - ACM SIGIR Forum,  - dl.acm.org) (… models, we have developed an approach to retrieval based on probabilistic language … in \n",
            "information retrieval in two senses. The first sense denotes an abstraction of the retrieval task …) (… models, we have developed an approach to retrieval based on probabilistic language … in \n",
            "information retrieval in two senses. The first sense denotes an abstraction of the retrieval task …)\n",
            "\n",
            "Found article: A study of smoothing methods for language models applied to ad hoc information retrieval (2017) (C Zhai, J Lafferty - ACM SIGIR Forum,  - dl.acm.org) (… to information retrieval are attractive and promising because they connect the problem of \n",
            "retrieval … smoothing and its influence on retrieval performance. We examine the sensitivity of …) (… to information retrieval are attractive and promising because they connect the problem of \n",
            "retrieval … smoothing and its influence on retrieval performance. We examine the sensitivity of …)\n",
            "\n",
            "Found article: A latent semantic model with convolutional-pooling structure for information retrieval (2014) (Y Shen, X He, J Gao, L Deng, G Mesnil - … on conference on information …,  - dl.acm.org) (… lexical matching for Web document retrieval. This is partially … have also been proposed for \n",
            "information retrieval (IR) [16][32]… as weakly-supervised information in training the model. In …) (… lexical matching for Web document retrieval. This is partially … have also been proposed for \n",
            "information retrieval (IR) [16][32]… as weakly-supervised information in training the model. In …)\n",
            "\n",
            "Found article: Integrating and evaluating neural word embeddings in information retrieval (2015) (G Zuccon, B Koopman, P Bruza… - Proceedings of the 20th …,  - dl.acm.org) (… in information retrieval. Specifically, we first show how word embeddings can be incorporated \n",
            "into a retrieval … building word embeddings have on retrieval effectiveness. The empirical …) (… in information retrieval. Specifically, we first show how word embeddings can be incorporated \n",
            "into a retrieval … building word embeddings have on retrieval effectiveness. The empirical …)\n",
            "\n",
            "Found article: Deep sentence embedding using long short-term memory networks: Analysis and application to information retrieval (2016) (H Palangi, L Deng, Y Shen, J Gao, X He… - … on Audio, Speech …,  - ieeexplore.ieee.org) (… Besides, we also include in Table IV two well-known information retrieval (IR) models, \n",
            "BM25 and PLSA, for the sake of benchmarking. The BM25 model uses the bag-of-words …) (… Besides, we also include in Table IV two well-known information retrieval (IR) models, \n",
            "BM25 and PLSA, for the sake of benchmarking. The BM25 model uses the bag-of-words …)\n",
            "\n",
            "Found article: [PDF][PDF] Leveraging linguistic structure for open domain information extraction (2015) (G Angeli, MJJ Premkumar… - Proceedings of the 53rd …,  - aclanthology.org) (Relation triples produced by open domain information extraction (open IE) systems are \n",
            "useful for question answering, inference, and other IE tasks. Traditionally these are extracted …) (Relation triples produced by open domain information extraction (open IE) systems are \n",
            "useful for question answering, inference, and other IE tasks. Traditionally these are extracted …)\n",
            "\n",
            "Found article: [BOOK][B] Text information retrieval systems (2017) (BR Boyce, BR Boyce, CT Meadow, DH Kraft, DH Kraft… -  - repo.iainbatusangkar.ac.id) (\"Information retrieval is a communication process that links an information user or seeker to … \n",
            "and retrieval. This book's purpose is to teach people who will be searching or designing text …) (\"Information retrieval is a communication process that links an information user or seeker to … \n",
            "and retrieval. This book's purpose is to teach people who will be searching or designing text …)\n",
            "\n",
            "Found article: [BOOK][B] Evaluating Information Retrieval and Access Tasks: NTCIR's Legacy of Research Impact (2021) (T Sakai, DW Oard, N Kando -  - library.oapen.org) (… the progression of the academic field of information retrieval research from a rather limited \n",
            "library focused research topic to a rich multi-faceted study of information access of all forms of …) (… the progression of the academic field of information retrieval research from a rather limited \n",
            "library focused research topic to a rich multi-faceted study of information access of all forms of …)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "# Define your search query\n",
        "query = \"information retrieval\"\n",
        "\n",
        "# Specify the start and end year for your date filter\n",
        "start_year = 2013  # 10 years ago\n",
        "end_year = 2023  # Current year\n",
        "\n",
        "# Create a function to fetch and parse search results\n",
        "def fetch_search_results(query, start=0):\n",
        "    url = f\"https://scholar.google.com/scholar?start={start}&q={query}&as_ylo={start_year}&as_yhi={end_year}\"\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    return soup.find_all('div', class_='gs_ri'), soup.find('a', {'aria-label': 'Next'})\n",
        "\n",
        "# Create a function to extract article details\n",
        "def extract_article_details(result):\n",
        "    title = result.find('h3', class_='gs_rt').get_text()\n",
        "    authors = result.find('div', class_='gs_a').get_text()\n",
        "    year = re.search(r'\\d{4}', authors).group()  # Extract the publication year\n",
        "    authors = re.sub(r'\\d{4}', '', authors).strip()  # Remove the year from authors string\n",
        "    venue = result.find('div', class_='gs_a').find_next_sibling('div').get_text()\n",
        "    abstract = result.find('div', class_='gs_rs').get_text()\n",
        "    \n",
        "    return {\n",
        "        'title': title,\n",
        "        'authors': authors,\n",
        "        'year': year,\n",
        "        'venue': venue,\n",
        "        'abstract': abstract\n",
        "    }\n",
        "\n",
        "# Collect up to 1000 articles that match your criteria\n",
        "articles = []\n",
        "start = 0\n",
        "while start < 1000:\n",
        "    search_results, next_page = fetch_search_results(query, start)\n",
        "    if not search_results:\n",
        "        break\n",
        "\n",
        "    for result in search_results:\n",
        "        article_info = extract_article_details(result)\n",
        "        articles.append(article_info)\n",
        "        print(f\"\\nFound article: {article_info['title']} ({article_info['year']}) ({article_info['authors']}) ({article_info['venue']}) ({article_info['abstract']})\")\n",
        "    \n",
        "    # Check if there are more search results pages to fetch\n",
        "    \n",
        "        start += 1  # Google Scholar typically shows 10 results per page\n",
        "    if not next_page:\n",
        "        break\n",
        "\n",
        "# Now you have a list of articles with title, authors, year, venue, and abstract\n",
        "# You can process this list further as needed\n",
        "len(articles)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCQpbJnwTxAB"
      },
      "source": [
        "Do either of the question-4 tasks given below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GT3CNj_V9-pb"
      },
      "source": [
        "Question 4 (10 points): Write python code to collect 1000 posts from Twitter, or Facebook, or Instagram. You can either use hashtags, keywords, user_name, user_id, or other information to collect the data.\n",
        "\n",
        "The following information needs to be collected:\n",
        "\n",
        "(1) User_name\n",
        "\n",
        "(2) Posted time\n",
        "\n",
        "(3) Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FymVNKVi9-pb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOeAr9TJTBgS"
      },
      "source": [
        "Question 4 (10 points):\n",
        "\n",
        "In this task, you are required to identify and utilize online tools for web scraping data from websites without the need for coding, with a specific focus on Parsehub. The objective is to gather data and save it in formats like CSV, Excel, or any other suitable file format.\n",
        "\n",
        "You have to mention an introduction to the tool which ever you prefer to use, steps to follow for web scrapping and the final output of the data collected.\n",
        "\n",
        "Upload a document (Word or PDF File) in the same repository and you can add the link in the ipynb file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N20TjXLmTG1u"
      },
      "outputs": [],
      "source": [
        "# Upload the link to the document here\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
